# RL-Based Queue Management System ğŸ¦

**Reinforcement Learning for Dynamic Staffing Optimization in Service Operations**

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-green.svg)](https://streamlit.io/)
[![Kafka](https://img.shields.io/badge/Kafka-3.0+-black.svg)](https://kafka.apache.org/)

## ğŸ“‹ Overview

This project implements a **Deep Q-Network (DQN)** based reinforcement learning system for real-time queue management and dynamic staffing optimization. The system learns optimal staffing policies by balancing customer wait times, abandonment rates, and operational costs.

### Key Features

- âœ… **Deep Reinforcement Learning**: DQN agent with experience replay and target networks
- âœ… **Real-Time Simulation**: Kafka-based event streaming for production deployment
- âœ… **Multi-Objective Optimization**: Balances wait time, renege rate, and staffing cost
- âœ… **Human Factors**: Models teller fatigue and break management
- âœ… **Statistical Validation**: 300-episode Monte Carlo validation on real-world data
- âœ… **Production-Ready**: Complete ML pipeline from training to deployment

### Results

| Metric | Baseline | RL Agent | Improvement |
|--------|----------|----------|-------------|
| **Avg Wait Time** | 34.55 min | 3.92 min | **88% â†“** |
| **Renege Rate** | 10.30% | 1.30% | **87% â†“** |
| **Avg Tellers** | 7.52 | 7.25 | **3.5% â†“** |
| **Total Cost** | High | Low | **Better** |

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Docker (for Kafka)
- Git

### Installation

```bash
# Clone repository
git clone https://github.com/Mukund-31/el.git
cd el/7thsem

# Install dependencies
pip install -r requirements.txt

# Start Kafka (optional - for real-time streaming)
docker-compose up -d
```

### Run the System

**Option 1: ML Research Dashboard (Training & Validation)**
```bash
streamlit run ml_research_dashboard.py --server.port 8504
```
- Stage 1: Train RL agent on synthetic data
- Stage 2: Validate on real-world trace data
- View statistical comparison and results

**Option 2: Real-Time Operational Dashboard**
```bash
streamlit run dashboard.py --server.port 8503
```
- Real-time simulation with trained RL model
- Dynamic staffing decisions every 10 minutes
- Kafka event streaming (if enabled)

**Option 3: Kafka Consumer (Monitor Events)**
```bash
python kafka_consumer.py
```
- View real-time queue events
- Monitor RL decisions
- Track system performance

---

## ğŸ“Š System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ML Research Pipeline                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Training (Synthetic Data)                               â”‚
â”‚     â””â”€> 300 episodes, DQN learning                          â”‚
â”‚  2. Validation (Real-World Trace)                           â”‚
â”‚     â””â”€> queue_data.csv (560 customers, March 30)            â”‚
â”‚  3. Statistical Analysis                                     â”‚
â”‚     â””â”€> Paired t-tests, confidence intervals                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                   trained_model.pth
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Real-Time Deployment                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Dashboard â†’ Kafka Producer â†’ queue-events topic            â”‚
â”‚                                      â†“                       â”‚
â”‚                            Kafka Consumer (Monitor)          â”‚
â”‚                                      â†“                       â”‚
â”‚                         RL Agent (Inference)                 â”‚
â”‚                                      â†“                       â”‚
â”‚                    Staffing Decisions (ADD/REMOVE)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  RL Agent Details

### State Space (12 dimensions)
- `num_tellers`: Current staffing level (1-10)
- `current_queue`: Queue length (0-50)
- `avg_fatigue`: Average teller fatigue (0-1)
- `max_fatigue`: Maximum teller fatigue (0-1)
- `burnt_out_count`: Number of exhausted tellers
- `lobby_anger`: Customer frustration level (0-10)
- `predicted_arrivals_mean`: Expected arrivals
- `predicted_arrivals_ucb`: Upper confidence bound
- `prediction_uncertainty`: Forecast uncertainty
- `current_wait`: Average wait time (0-20 min)
- `hour_of_day`: Time context (9-17)
- `recent_renege_rate`: Abandonment rate (0-1)

### Action Space (4 actions)
- `ADD_TELLER`: Hire additional staff
- `REMOVE_TELLER`: Reduce staffing
- `GIVE_BREAK`: Send fatigued teller on 20-min break
- `DO_NOTHING`: Maintain current state

### Reward Function
```python
reward = -(wait_cost + renege_cost + fatigue_cost + staffing_cost) + anger_bonus - action_penalty
```

### Neural Network Architecture
- **Input**: 12-dimensional state vector
- **Hidden Layers**: [128, 64] neurons with ReLU activation
- **Output**: 4 Q-values (one per action)
- **Optimizer**: Adam (lr=0.001)
- **Loss**: Huber Loss (smooth L1)

---

## ğŸ“ Project Structure

```
el/
â”œâ”€â”€ 7thsem/                          # Main project directory
â”‚   â”œâ”€â”€ dashboard.py                 # Real-time operational dashboard
â”‚   â”œâ”€â”€ ml_research_dashboard.py    # Training & validation dashboard
â”‚   â”œâ”€â”€ rl_optimization_agent.py    # DQN implementation
â”‚   â”œâ”€â”€ validation_framework.py     # Statistical validation
â”‚   â”œâ”€â”€ kafka_producer.py           # Event streaming producer
â”‚   â”œâ”€â”€ kafka_consumer.py           # Event streaming consumer
â”‚   â”œâ”€â”€ simple_comparison.py        # Direct trace comparison
â”‚   â”œâ”€â”€ trained_model.pth           # Trained RL model weights
â”‚   â”œâ”€â”€ docker-compose.yml          # Kafka setup
â”‚   â”œâ”€â”€ requirements.txt            # Python dependencies
â”‚   â”‚
â”‚   â”œâ”€â”€ Documentation/
â”‚   â”‚   â”œâ”€â”€ STATE_CALCULATION.md    # How states are computed
â”‚   â”‚   â”œâ”€â”€ BREAK_SYSTEM.md         # Break management guide
â”‚   â”‚   â”œâ”€â”€ KAFKA_GUIDE.md          # Kafka integration guide
â”‚   â”‚   â”œâ”€â”€ SIMULATION_BEHAVIOR.md  # Expected behavior
â”‚   â”‚   â”œâ”€â”€ OBJECTIVES_VERIFICATION.md  # Project objectives
â”‚   â”‚   â””â”€â”€ FINAL_RESULTS_SUMMARY.md    # Results analysis
â”‚   â”‚
â”‚   â””â”€â”€ Data/
â”‚       â””â”€â”€ queue_data.csv          # Real-world trace data
â”‚
â””â”€â”€ README.md                        # This file
```

---

## ğŸ”¬ Methodology

### 1. Training Phase
- **Environment**: Synthetic queue simulation
- **Episodes**: 300 training episodes
- **Exploration**: Îµ-greedy (Îµ: 1.0 â†’ 0.01)
- **Experience Replay**: 10,000 transitions
- **Target Network**: Updated every 10 episodes

### 2. Validation Phase
- **Data**: Real-world trace (queue_data.csv)
- **Method**: Replay historical arrivals
- **Comparison**: RL Agent vs. Rule-Based Baseline
- **Metrics**: Wait time, renege rate, cost, served customers

### 3. Deployment Phase
- **Mode**: Real-time simulation
- **Decision Frequency**: Every 10 minutes
- **Event Streaming**: Kafka topics
- **Monitoring**: Live dashboard + consumer logs

---

## ğŸ“ˆ Key Insights

### 1. Proactive Staffing
The RL agent learns to **add tellers before** queue buildup by using predicted arrivals:
```
09:20 - Predicted rush at 09:30 â†’ ADD_TELLER
09:30 - Rush arrives â†’ Queue stays low âœ…
```

### 2. Cost Optimization
When queue is empty, the agent **reduces excess staffing**:
```
Queue = 0, Tellers = 10 â†’ REMOVE_TELLER
Queue = 0, Tellers = 9 â†’ REMOVE_TELLER
...stabilizes at 5-6 tellers
```

### 3. Human Factors
The agent learns to **give breaks** to prevent burnout:
```
Teller 3 fatigue = 0.78 â†’ GIVE_BREAK
Teller 3 on break (20 min) â†’ Fatigue resets to 0.0
Teller 3 returns refreshed âœ…
```

---

## ğŸ“ Academic Use

This project demonstrates:
- **Queuing Theory**: M/M/c queue modeling with time-varying arrivals
- **Operations Research**: Multi-objective cost optimization
- **Machine Learning**: Deep Q-Learning with function approximation
- **Statistical Validation**: Hypothesis testing, confidence intervals
- **Production Deployment**: Event-driven architecture with Kafka

### Citation
If you use this work, please cite:
```
@misc{queue_rl_2024,
  author = {Mukund},
  title = {RL-Based Queue Management System},
  year = {2024},
  publisher = {GitHub},
  url = {https://github.com/Mukund-31/el}
}
```

---

## ğŸ“„ License

This project is available for academic and research purposes.

---

## ğŸ¤ Contributing

Contributions are welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Submit a pull request

---

## ğŸ“§ Contact

For questions or collaboration:
- GitHub: [@Mukund-31](https://github.com/Mukund-31)
- Repository: [https://github.com/Mukund-31/el](https://github.com/Mukund-31/el)

---

## ğŸ™ Acknowledgments

- PyTorch for deep learning framework
- Streamlit for dashboard framework
- Apache Kafka for event streaming
- Real-world queue data from banking operations

---

**Built with â¤ï¸ for advancing AI in operations management**
